{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =           18     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.93147D+00    |proj g|=  1.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "   18     19     20      1     0     0   8.265D-05   1.806D-04\n",
      "  F =   1.8061530956048799E-004\n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder\n",
    "\n",
    "X = np.array([\n",
    "    [1, '周六', '吃饭', '晴天', '轻松', '清零', '精彩'],\n",
    "    [2, '周日', '吃饭', '阴天', '轻松', '清零', '精彩'],\n",
    "    [3, '周日', '吃饭', '晴天', '轻松', '清零', '精彩'],\n",
    "    [4, '周六', '吃饭', '阴天', '轻松', '清零', '精彩'],\n",
    "    [5, '周间', '吃饭', '晴天', '轻松', '清零', '精彩'],\n",
    "    [6, '周六', '逛街', '晴天', '轻松', '平缓', '无聊'],\n",
    "    [7, '周日', '逛街', '晴天', '适中', '平缓', '无聊'],\n",
    "    [8, '周日', '逛街', '晴天', '轻松', '平缓', '精彩'],\n",
    "    [9, '周日', '逛街', '阴天', '适中', '平缓', '精彩'],\n",
    "    [10, '周六', '学习', '雨天', '轻松', '严峻', '无聊'],\n",
    "    [11, '周间', '学习', '雨天', '繁重', '严峻', '精彩'],\n",
    "    [12, '周间', '吃饭', '晴天', '繁重', '严峻', '无聊'],\n",
    "    [13, '周六', '逛街', '晴天', '适中', '清零', '精彩'],\n",
    "    [14, '周间', '逛街', '阴天', '适中', '清零', '精彩'],\n",
    "    [15, '周日', '逛街', '晴天', '轻松', '平缓', '无聊'],\n",
    "    [16, '周间', '吃饭', '晴天', '繁重', '严峻', '精彩'],\n",
    "    [17, '周六', '吃饭', '阴天', '适中', '平缓', '精彩'],\n",
    "])\n",
    "y = np.array(\n",
    "    ['是', '是', '是', '是', '是', '是', '是', '是',\n",
    "     '否', '否', '否', '否', '否', '否', '否', '否', '否']\n",
    ")\n",
    "X = OneHotEncoder().fit_transform(X[:, 1:7])\n",
    "y = LabelBinarizer().fit_transform(y).squeeze()\n",
    "\n",
    "train_index = [0, 1, 2, 5, 6, 9, 13, 14, 15, 16]\n",
    "test_index = [3, 4, 7, 8, 10, 11, 12]\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[train_index, :], X[test_index, :], y[train_index], y[test_index]\n",
    "\n",
    "clf = LogisticRegression(penalty='none', verbose=True)  # 无正则项 输出日志\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.19744231e-14, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [3.45002693e-10, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [9.99999999e-01, 8.41179268e-10, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 4.23642522e-19, 1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 2.94646658e-47, 1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 5.95930974e-17, 1.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack((clf.predict_proba(X_test), OneHotEncoder().fit_transform(y_test[:, np.newaxis]).toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.19744231e-14, 1.00000000e+00],\n",
       "       [3.45002693e-10, 1.00000000e+00],\n",
       "       [9.99999999e-01, 8.41179268e-10],\n",
       "       [1.00000000e+00, 4.23642522e-19],\n",
       "       [1.00000000e+00, 2.94646658e-47],\n",
       "       [1.00000000e+00, 5.95930974e-17],\n",
       "       [0.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
